{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from builtins import super\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ML(object):\n",
    "    def __init__(self, name='ML'):\n",
    "        self.name = name\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope('model'):\n",
    "                self.initialize_graph()\n",
    "            with tf.name_scope('global_ops'):\n",
    "                self.init = tf.initialize_all_variables()\n",
    "            \n",
    "    def initialize_graph(self):\n",
    "        \"\"\"Already in graph scope.\"\"\"\n",
    "        raise NotImplementedError('Method initialize_graph() must be implemented.')\n",
    "    \n",
    "    def inference(self, X):\n",
    "        \"\"\"Compute inference model over data X and return the result.\"\"\"\n",
    "        raise NotImplementedError('Method inference(X) must be implemented.')\n",
    "    \n",
    "    def loss(self, X, Y):\n",
    "        \"\"\"Compute loss over training data X and expected outputs Y.\"\"\"\n",
    "        raise NotImplementedError('Method loss(X, Y) must be implemented.')\n",
    "    \n",
    "    def inputs(self):\n",
    "        \"\"\"Read/generate input training data X and expected outputs Y.\"\"\"\n",
    "        raise NotImplementedError('Method inputs() must be implemented.')\n",
    "    \n",
    "    def train(self, total_loss):\n",
    "        \"\"\"Train / adjust model parameters according to computed total loss.\"\"\"\n",
    "        raise NotImplementedError('Method train(total_loss) must be implemented.')\n",
    "        \n",
    "    def evaluate(self, sess, X, Y):\n",
    "        \"\"\"Evaluate the resulting trained model.\"\"\"\n",
    "        raise NotImplementedError('Method evaluate(sess, X, Y) must be implemented.')\n",
    "        \n",
    "    def run_training(self, training_steps, print_every=10, save_every=1000):\n",
    "        save_dir = os.path.join('saves', self.name)\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            X, Y = self.inputs()\n",
    "        \n",
    "            total_loss = self.loss(X, Y)\n",
    "            train_op = self.train(total_loss)\n",
    "            \n",
    "            # Create a saver.\n",
    "            saver = tf.train.Saver()\n",
    "                \n",
    "        sess = tf.Session(graph=self.graph)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "        # Load the latest training checkpoint, if it exists\n",
    "        ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            # Restores from checkpoint\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            initial_step = int(ckpt.model_checkpoint_path.rsplit('-', 1)[1])\n",
    "        else:\n",
    "            sess.run(self.init)\n",
    "            initial_step = 0\n",
    "        \n",
    "        # The actual training loop\n",
    "        for step in range(initial_step, training_steps):\n",
    "            sess.run([train_op])\n",
    "            \n",
    "            # for debugging and learning purposes, see how the loss gets\n",
    "            # decremented thru training steps\n",
    "            if step % print_every == 0:\n",
    "                print('loss: ', sess.run(total_loss))\n",
    "            \n",
    "            # Model checkpoint\n",
    "            if step % save_every == 0 and step > 0:\n",
    "                print('Saving in...')\n",
    "                saver.save(sess, save_dir, global_step=step)\n",
    "                \n",
    "        print('Saving out...')\n",
    "        saver.save(sess, save_dir, global_step=training_steps)\n",
    "        \n",
    "        self.evaluate(sess, X, Y)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(ML):\n",
    "    def __init__(self, name='LR'):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "    def initialize_graph(self):\n",
    "        # initialize variables/model parameters\n",
    "        self.W = tf.Variable(tf.zeros([2, 1]), name=\"weights\")\n",
    "        self.b = tf.Variable(0., name=\"bias\")\n",
    "        \n",
    "    def inference(self, X):\n",
    "        return tf.matmul(X, self.W) + self.b\n",
    "    \n",
    "    def loss(self, X, Y):\n",
    "        beta = 0.001\n",
    "        Y_predicted = self.inference(X)\n",
    "        return (tf.reduce_sum(tf.squared_difference(Y, Y_predicted))) #+\n",
    "                #beta * (tf.nn.l2_loss(self.W) + tf.nn.l2_loss(self.b)))\n",
    "    \n",
    "    def inputs(self):\n",
    "        weight_age = [[84, 46], [73, 20], [65, 52], [70, 30], [76, 57],\n",
    "                      [69, 25], [63, 28], [72, 36], [79, 57], [75, 44],\n",
    "                      [27, 24], [89, 31], [65, 52], [57, 23], [59, 60],\n",
    "                      [69, 48], [60, 34], [79, 51], [75, 50], [82, 34],\n",
    "                      [59, 46], [67, 23], [85, 37], [55, 40], [63, 30]]\n",
    "        blood_fat_content = [354, 190, 405, 263, 451,\n",
    "                             302, 288, 385, 402, 365,\n",
    "                             209, 290, 346, 254, 395,\n",
    "                             434, 220, 374, 308, 220,\n",
    "                             311, 181, 274, 303, 244]\n",
    "        return tf.to_float(weight_age), tf.to_float(blood_fat_content)\n",
    "\n",
    "    def train(self, total_loss):\n",
    "        learning_rate = 0.0000001\n",
    "        return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "        \n",
    "    \n",
    "    def evaluate(self, sess, X, Y):\n",
    "        print(sess.run(self.inference([[80., 23.]])))\n",
    "        print(sess.run(self.inference([[65., 23.]])))\n",
    "        print(sess.run(self.inference([[57., 23.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  7.60877e+06\n",
      "loss:  5.22567e+06\n",
      "loss:  5.11695e+06\n",
      "loss:  5.01565e+06\n",
      "loss:  4.92128e+06\n",
      "loss:  4.83335e+06\n",
      "loss:  4.75144e+06\n",
      "loss:  4.67511e+06\n",
      "loss:  4.60401e+06\n",
      "loss:  4.53777e+06\n",
      "Saving out...\n",
      "[[ 315.59927368]]\n",
      "[[ 278.35565186]]\n",
      "[[ 258.49240112]]\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.run_training(100000, print_every=10000, save_every=100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
